---
title: "Cognitive and Sociolectal Constraints on the Placement of 'lai' as a Telicity Marker in Mandarin Chinese"
author: "Xu Zhang"
output: 
   html_document:
    toc: true
    toc_depth: 1
    toc_float: true
date: "2025-06-01"

---
# Introduction:
In Mandarin Chinese, 
Why a variationist perspective
What are key findings:

Methods: 

# Setting up: data reading and cleaning
```{r loading packages,echo = FALSE, eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(car)         # to calculate VIFs
library(Hmisc)       # to calculate C values
library(party)       # for ctrees and CRF
#install.packages("lattice")
library(lattice)
library(lme4)        # for mixed-effects regression
library(MuMIn)       # for PSeudo R2 measures
library(effects)     # for partial effects plot
library(report)      # for description of various objects
library(parameters)  # to examine model effects
library(performance) # to assess and compare model performance
#install.packages("broom.mixed") #for plotting 
#install.packages("gt")
library(broom.mixed)
library(gt)
library(knitr)
#install.packages("gmodels")
library(gmodels)
```


```{r set-up, echo = TRUE, eval = TRUE}
OUT<-read.csv("DCC_out.csv", sep=";", stringsAsFactors=TRUE) 
OUT_dis <- distinct(OUT, Text, .keep_all = TRUE) # removing duplicates
out_data<- OUT_dis[rowSums(is.na(OUT_dis) | OUT_dis == "") < ncol(OUT_dis), ] # removing NA/empty observations
summary(out_data)
```

In total, we obtained 701 observations

# Data overview
```{r data overview, fig.cap="Figure 1: data overview", echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
library(base)
out_data$Response<-as.factor(out_data$Response)
out_data$NP_Length<- as.numeric(out_data$NP_Length)
out_data$Structural_priming<-as.factor(out_data$Structural_priming)
out_data$NP_Givenness<-as.factor(out_data$NP_Givenness)
out_data$NP_Concreteness<- as.factor(out_data$NP_Concreteness)
out_data$Verb_Syllables<-as.numeric(out_data$Verb_Syllables)
out_data$TimePeriod<- as.factor(out_data$TimePeriod)
out_data$TimePeriod2<- as.factor(out_data$TimePeriod2)
out_data$Genre<- as.factor(out_data$Genre)
out_data$Formality<-as.factor(out_data$Formality)
out_data$Modal<-as.factor(out_data$Modal)
out_data$Region<- as.factor(out_data$Region)
#the frequency of responses
response_counts <- table(out_data$Response)
piechart<-pie(response_counts, 
    main = "Response Distribution", 
    col = rainbow(length(response_counts)), 
    labels = paste(names(response_counts), response_counts, sep=": ")) 

```

# data annotation


```{r variables, echo = TRUE, eval=TRUE}
library(knitr)

variables <- data.frame(
    Variable = c("Response", "NP_Length", "Structural_priming", "NP_Givenness", "NP_Concreteness", "Verb_Syllables", "TimePeriod", "TimePeriod2", "Genre", "Formality", "Modal", "Region"),
    Type = c("response variable", "numeric", "factor", "factor", "factor", "numeric", "factor", "factor", "factor", "factor", "factor", "factor"),
    Explanation = c("continuous vs. split", "Object NP length - character numbers ", "Yes vs. No", "Given vs. New", "Concrete vs. Non-concrete", "the syllables of verbs in CDC constructions", "decade-based division", "sequencially labelling each two decades as a time period - 1, 2, 3, 4, 5, 6", "9 levels: news report, fiction, fiction-translation, interview, TV, essay, essay-translation, biography, online", "genres being divided according to formality: higher vs. lower", "genres being divided into written vs. spoken", "three regions: Mainland, Taiwan and Hong Kong")
)

# Render as a table
kable(variables, caption = "Table 1: Data Annotation")

```


# The Diachornic Change of the Two Variants' Frequency

```{r response counts, fig.cap="Figure 2: Response Frequency Across Time Periods", echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
response_counts <- out_data %>%
  group_by(TimePeriod, Response) %>%
  summarise(Frequency = n()) 

ggplot(response_counts, aes(x = TimePeriod, y = Frequency, color = Response, group = Response)) +
  geom_line(size = 1) +  # Creates trend lines
  geom_point(size = 3) +  # Adds data points
  labs(title = "Response Frequency Across Time Periods",
       x = "Time Period",
       y = "Frequency",
       color = "Response") +
  theme_minimal()
```


# Plotting NP Length vs. Variants 
```{r NP Length distribution, fig.cap="Figure 3: Log_NP_Length vs. Response", echo = TRUE, eval = TRUE, fig.width=6, fig.height=4}
out_data$log_NP_Length <- log(out_data$NP_Length +1)  # Adding 1 prevents log(0) issues

ggplot(out_data, aes(x = Response, y = log_NP_Length)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  stat_summary(fun = mean, geom = "point", shape = 18, color = "red", size = 3) +  # Mean (Red Diamond)
  stat_summary(fun = median, geom = "point", shape = 8, color = "blue", size = 3) +  # Median (Blue Star)
  labs(title = "Boxplot of Log-Transformed NP_Length vs. Response",
       x = "Response",
       y = "Log(NP_Length)") +
  theme_minimal()
```

## the correlation between VP and NP weight
```{r corelation between VP and NP weight, echo = TRUE, eval = TRUE}
cor(out_data$Verb_Syllables, out_data$log_NP_Length)
```

weak positive pearson correlation: meaning it is slightly more likely that heavier NPs occur in constructions with heavier VPs. 

# Identifying important constraints on DCC variation 
## conditional inference tree

```{r ctree, fig.cap="Figure 4: Ctree showing decision-making process based on statistically significant splits", echo = TRUE, eval = TRUE, fig.width=8, fig.height=6}

tree = ctree(Response ~ TimePeriod2 + log_NP_Length + NP_Givenness + Structural_priming + NP_Concreteness + Verb_Syllables + Genre + Region, data = out_data,control=ctree_control(maxdepth=3)) # maxdepth specifies the height of the tree. Reduce to reduce complexity.
plot(tree)

```
assessing mdel fitting
```{r tree evaluation, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
ctree.pred <- unlist(treeresponse(tree))[c(FALSE, TRUE)]
somers2(ctree.pred, as.numeric(out_data$Response) - 1)
```

## plotting factor importance using CRF
```{r CRF model fitting, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}

set.seed(123) # esnures that we can reproduce results
forest = cforest(Response ~ TimePeriod2 + log_NP_Length + NP_Givenness + Structural_priming + NP_Concreteness + Verb_Syllables + Genre + Formality + Modal + Region, data = out_data)

#### calculate variable importance ranking, takes some time
forest.varimp = varimp(forest, conditional = FALSE) 

#### model C index
#### C ranges between 0.5 an 1; the closer to 1, the better the model
prob2.rf <- unlist(treeresponse(forest))[c(FALSE, TRUE)]
somerssmallcrf <- somers2(prob2.rf, as.numeric(out_data$Response) - 1)
somerssmallcrf["C"]

```
excellent predictability

plotting out CRF

```{r CRF plotting, fig.cap="Figure 5: Factor importance ranking" ,echo = TRUE, eval = TRUE, fig.width=6, fig.height=4}

### the dot plot visualizing the variable importance ranking
dotplot(sort(forest.varimp), xlab="Variable Importance", panel = function(x,y){
  panel.dotplot(x, y, col='darkblue', pch=16, cex=1.1)
  panel.abline(v=abs(min(forest.varimp)), col='red',
               lty='longdash', lwd=2)
}
) 
```


# How constraints regulating DCC variation -- GLMER

```{r mixed-effect model fitting,echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}

# defining reference response/i_variable level
out_data$Response <- relevel(out_data$Response, ref="Split")# reference level is split, thus predicted odds are for continuous
out_data$NP_Concreteness<-relevel(out_data$NP_Concreteness, ref="Non-concrete")

mixed_model <- glmer(Response ~ TimePeriod2 + log_NP_Length + NP_Concreteness + Verb_Syllables + Formality + (1|Genre) + (1|Region), data = out_data, family=binomial)
print(summary(mixed_model), corr = F)

# Tidy the mixed_model output
tidy_model <- tidy(mixed_model)

tidy_fixed <- tidy_model %>%
  filter(effect == "fixed") %>%  # Removes random effect estimates
  select(-group)  # Excludes the 'group' column

tidy_fixed %>%
  gt() %>%
  tab_header(title = "Table 2: Model Results (Fixed Effects Only)") %>%
  fmt_number(columns = c(estimate, std.error, p.value), decimals = 5) 
```

model assessment

```{r model evaluation, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}

model_values<-somers2(binomial()$linkinv(fitted(mixed_model)), as.numeric(out_data$Response) -1)
kable(model_values)
```

C (Concordance Index) = 0.97 → Measures discrimination ability. A value close to 1 suggests the model is highly effective at distinguishing between outcomes.
Dxy (Somers' D Rank Correlation) = 0.93 → Indicates strong rank correlation between predicted probabilities and actual responses. High values suggest robust predictive power.

assessing to what extent the model explains variance

```{r model explainability, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
# The proportion of correctly predicted values is calculated by cross tabulating the observed and predicted values.

fitted <- fitted(mixed_model)
predicted <- ifelse(fitted >= .5, 1,0)
a <- data.frame(out_data, predicted)
cross_table<-CrossTable(out_data$Response, a$predicted)
kable(cross_table)
```

Pseudo R2 measures 
(see https://www.rdocumentation.org/packages/MuMIn/versions/1.40.4/topics/r.squaredGLMM)
R2m: Pseudo-R2 (marginal) -- represents the % variance explained by fixed factors
R2c: Pseudo-R2 (conditional) -- is interpreted as variance explained by both fixed and random factors (i.e. the entire model),
```{r model r square, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
r_squared<-r.squaredGLMM(mixed_model)
kable(r_squared)
```

## Plotting all effects
```{r partial effects, fig.cap="Figure 6: Plotting the effect of all factors", echo = TRUE, eval = TRUE, fig.width=10, fig.height=10}
# Compute all effects for the mixed model
plot(allEffects(mixed_model))
```

